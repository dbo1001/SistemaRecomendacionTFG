{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recomendación con LightFM\n",
    "En este notebook se obtienen los distintos tipos de modelos (colaborativo, basado en contenido e híbrido) con el conjunto de datos de MovieLens y la librería LightFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importar todo lo necesario\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del número de hilos del procesador\n",
    "cpu_threads = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r ml_data_df\n",
    "%store -r ml_users_df\n",
    "%store -r ml_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "ml_dataset = Dataset()\n",
    "ml_dataset.fit(ml_data_df['Id Usuario'], ml_data_df['Id Película'])\n",
    "ml_dataset.fit_partial(users=ml_users_df['Id Usuario'], items=ml_items_df['Id Película'],\n",
    "                    user_features=ml_users_df['Género'], item_features=ml_items_df['Título'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(ml_interactions, ml_weights) = ml_dataset.build_interactions((row['Id Usuario'], row['Id Película'], row['Valoración']) for index, row in ml_data_df.iterrows())\n",
    "ml_item_features = ml_dataset.build_item_features((row['Id Película'], [row['Título']]) for index, row in ml_items_df.iterrows())\n",
    "ml_user_features = ml_dataset.build_user_features((row['Id Usuario'], [row['Género']]) for index, row in ml_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_train, ml_test = random_train_test_split(ml_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ml_data.pickle', 'wb') as f:\n",
    "    pickle.dump([ml_train, ml_test, ml_item_features, ml_user_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('ml_data.pickle', 'rb') as f:\n",
    "    ml_train, ml_test, ml_item_features, ml_user_features = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_collab_model = LightFM(loss='warp')\n",
    "ml_collab_model.fit(ml_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "ml_collab_precision_at_k = precision_at_k(ml_collab_model, ml_test, \n",
    "                                          train_interactions=ml_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "ml_collab_auc_score = auc_score(ml_collab_model, ml_test, train_interactions=ml_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_collab_predictions = ml_collab_model.predict_rank(ml_test, \n",
    "                                                     train_interactions=ml_train, \n",
    "                                                     num_threads=cpu_threads,check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_hybrid_model = LightFM(loss='warp')\n",
    "ml_hybrid_model.fit(ml_train, item_features=ml_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "ml_hybrid_precision_at_k = precision_at_k(ml_hybrid_model, ml_test, train_interactions=ml_train, \n",
    "                                          item_features=ml_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "ml_hybrid_auc_score = auc_score(ml_hybrid_model, ml_test, train_interactions=ml_train, \n",
    "                                item_features=ml_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_hybrid_predictions = ml_hybrid_model.predict_rank(ml_test, train_interactions=ml_train, \n",
    "                                                     item_features=ml_item_features,  \n",
    "                                                     num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_content_model = LightFM(loss='warp')\n",
    "ml_content_model.fit(ml_train, user_features=ml_user_features, item_features=ml_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "ml_content_precision_at_k = precision_at_k(ml_content_model, ml_test, train_interactions=ml_train, \n",
    "                                           user_features=ml_user_features, \n",
    "                                           item_features=ml_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "ml_content_auc_score = auc_score(ml_content_model, ml_test, train_interactions=ml_train, \n",
    "                                 user_features=ml_user_features, \n",
    "                                 item_features=ml_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_content_predictions = ml_content_model.predict_rank(ml_test, train_interactions=ml_train, \n",
    "                                                       item_features=ml_item_features, \n",
    "                                                       user_features=ml_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ml_models.pickle', 'wb') as f:\n",
    "    pickle.dump([ml_collab_model, ml_hybrid_model, ml_content_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('ml_models.pickle', 'rb') as f:\n",
    "    ml_collab_model, ml_hybrid_model, ml_content_model = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ml_results.pickle', 'wb') as f:\n",
    "    pickle.dump([ml_collab_precision_at_k, ml_collab_auc_score, ml_collab_predictions,\n",
    "                ml_hybrid_precision_at_k, ml_hybrid_auc_score, ml_hybrid_predictions,\n",
    "                ml_content_precision_at_k, ml_content_auc_score, ml_content_predictions], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r anime_data_df\n",
    "%store -r anime_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "anime_dataset = Dataset()\n",
    "anime_dataset.fit(anime_data_df['Id Usuario'], anime_data_df['Id Anime'])\n",
    "anime_dataset.fit_partial(items=anime_items_df['Id Anime'], item_features=anime_items_df['Título'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(anime_interactions, anime_weights) = anime_dataset.build_interactions((row['Id Usuario'], row['Id Anime'], row['Valoración']) for index, row in anime_data_df.iterrows())\n",
    "anime_item_features = anime_dataset.build_item_features((row['Id Anime'], [row['Título']]) for index, row in anime_items_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime_train, anime_test = random_train_test_split(anime_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anime_data.pickle', 'wb') as f:\n",
    "    pickle.dump([anime_train, anime_test, anime_item_features, anime_user_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('anime_data.pickle', 'rb') as f:\n",
    "    anime_train, anime_test, anime_item_features, anime_user_features = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "anime_collab_model = LightFM(loss='warp')\n",
    "anime_collab_model.fit(anime_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "anime_collab_precision_at_k = precision_at_k(anime_collab_model, anime_test, \n",
    "                                             train_interactions=anime_train, k=10, num_threads=cpu_threads, \n",
    "                                             check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "anime_collab_auc_score = auc_score(anime_collab_model, anime_test, \n",
    "                                   train_interactions=anime_train, num_threads=cpu_threads, check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "anime_collab_predictions = anime_collab_model.predict_rank(anime_test, \n",
    "                                                           train_interactions=anime_train, \n",
    "                                                           num_threads=cpu_threads,\n",
    "                                                           check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "anime_hybrid_model = LightFM(loss='warp')\n",
    "anime_hybrid_model.fit(anime_interactions, item_features=anime_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "anime_hybrid_precision_at_k = precision_at_k(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                             item_features=anime_item_features, k=10, num_threads=cpu_threads, \n",
    "                                             check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "anime_hybrid_auc_score = auc_score(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                item_features=anime_item_features, num_threads=cpu_threads, check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "anime_hybrid_predictions = anime_hybrid_model.predict_rank(anime_test, \n",
    "                                                           train_interactions=anime_train, \n",
    "                                                           item_features=anime_item_features, \n",
    "                                                           num_threads=cpu_threads,\n",
    "                                                           check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anime_models.pickle', 'wb') as f:\n",
    "    pickle.dump([anime_collab_model, anime_hybrid_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('anime_models.pickle', 'rb') as f:\n",
    "    anime_collab_model, anime_hybrid_model = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anime_results.pickle', 'wb') as f:\n",
    "    pickle.dump([anime_collab_precision_at_k, anime_collab_auc_score, anime_collab_predictions,\n",
    "                anime_hybrid_precision_at_k, anime_hybrid_auc_score, anime_hybrid_predictions], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book-Crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r bc_data_df\n",
    "%store -r bc_users_df\n",
    "%store -r bc_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "bc_dataset = Dataset()\n",
    "bc_dataset.fit(bc_data_df['Id Usuario'], bc_data_df['ISBN'])\n",
    "bc_dataset.fit_partial(users=bc_users_df['Id Usuario'], items=bc_items_df['ISBN'],\n",
    "                    user_features=bc_users_df['Edad'], item_features=bc_items_df['Título'])\n",
    "\n",
    "#num_users, num_items = bc_dataset.interactions_shape()\n",
    "#print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "# Obtención de las matrices\n",
    "(bc_interactions, bc_weights) = bc_dataset.build_interactions((row['Id Usuario'], row['ISBN'], row['Valoración']) for index, row in bc_data_df.iterrows())\n",
    "bc_item_features = bc_dataset.build_item_features((row['ISBN'], [row['Título']]) for index, row in bc_items_df.iterrows())\n",
    "bc_user_features = bc_dataset.build_user_features((row['Id Usuario'], [row['Edad']]) for index, row in bc_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_train, bc_test = random_train_test_split(bc_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bc_data.pickle', 'wb') as f:\n",
    "    pickle.dump([bc_train, bc_test, bc_item_features, bc_user_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('bc_data.pickle', 'rb') as f:\n",
    "    bc_train, bc_test, bc_item_features, bc_user_features = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_collab_model = LightFM(loss='warp')\n",
    "bc_collab_model.fit(bc_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "bc_collab_precision_at_k = precision_at_k(bc_collab_model, bc_test, \n",
    "                                          train_interactions=bc_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "bc_collab_auc_score = auc_score(bc_collab_model, bc_test, \n",
    "                                train_interactions=bc_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_collab_predictions = bc_collab_model.predict_rank(bc_test, \n",
    "                                                     train_interactions=bc_train, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_hybrid_model = LightFM(loss='warp')\n",
    "bc_hybrid_model.fit(bc_train, item_features=bc_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "bc_hybrid_precision_at_k = precision_at_k(bc_hybrid_model, bc_test, train_interactions=bc_train, \n",
    "                                          item_features=bc_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "bc_hybrid_auc_score = auc_score(bc_hybrid_model, bc_test, train_interactions=bc_train, \n",
    "                                item_features=bc_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_hybrid_predictions = bc_hybrid_model.predict_rank(bc_test, \n",
    "                                                     train_interactions=bc_train, \n",
    "                                                     item_features=bc_item_features, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_content_model = LightFM(loss='warp')\n",
    "bc_content_model.fit(bc_train, \n",
    "                     user_features=bc_user_features, \n",
    "                     item_features=bc_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "bc_content_precision_at_k = precision_at_k(bc_content_model, bc_test, train_interactions=bc_train, \n",
    "                                           user_features=bc_user_features,\n",
    "                                           item_features=bc_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "bc_content_auc_score = auc_score(bc_content_model, bc_test, train_interactions=bc_train, \n",
    "                                 user_features=bc_user_features,\n",
    "                                 item_features=bc_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_content_predictions = bc_content_model.predict_rank(bc_test, train_interactions=bc_train, \n",
    "                                                       item_features=bc_item_features, \n",
    "                                                       user_features=bc_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bc_models.pickle', 'wb') as f:\n",
    "    pickle.dump([bc_collab_model, bc_hybrid_model, bc_content_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('bc_models.pickle', 'rb') as f:\n",
    "    bc_collab_model, bc_hybrid_model, bc_content_model = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('bc_results.pickle', 'wb') as f:\n",
    "    pickle.dump([bc_collab_precision_at_k, bc_collab_auc_score, bc_collab_predictions,\n",
    "                bc_hybrid_precision_at_k, bc_hybrid_auc_score, bc_hybrid_predictions,\n",
    "                bc_content_precision_at_k, bc_content_auc_score, bc_content_predictions], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LastFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r lf_data_df\n",
    "%store -r lf_users_df\n",
    "%store -r lf_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "lf_dataset = Dataset()\n",
    "lf_dataset.fit(lf_data_df['Id Usuario'], lf_data_df['Id Artista'])\n",
    "lf_dataset.fit_partial(users=lf_users_df['Id Usuario'], items=lf_items_df['Id Artista'],\n",
    "                    user_features=lf_users_df['Id Amigo'], item_features=lf_items_df['Nombre'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(lf_interactions, lf_weights) = lf_dataset.build_interactions((row['Id Usuario'], row['Id Artista'], row['Veces escuchado']) for index, row in lf_data_df.iterrows())\n",
    "lf_item_features = lf_dataset.build_item_features((row['Id Artista'], [row['Nombre']]) for index, row in lf_items_df.iterrows())\n",
    "lf_user_features = lf_dataset.build_user_features((row['Id Usuario'], [row['Id Amigo']]) for index, row in lf_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lf_train, lf_test = random_train_test_split(lf_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lf_data.pickle', 'wb') as f:\n",
    "    pickle.dump([lf_train, lf_test, lf_item_features, lf_user_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('lf_data.pickle', 'rb') as f:\n",
    "    lf_train, lf_test, lf_item_features, lf_user_features = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_collab_model = LightFM(loss='warp')\n",
    "lf_collab_model.fit(lf_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "lf_collab_precision_at_k = precision_at_k(lf_collab_model, lf_test, \n",
    "                                          train_interactions=lf_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "lf_collab_auc_score = auc_score(lf_collab_model, lf_test, \n",
    "                                train_interactions=lf_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_collab_predictions = lf_collab_model.predict_rank(lf_test, \n",
    "                                                     train_interactions=lf_train, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_hybrid_model = LightFM(loss='warp')\n",
    "lf_hybrid_model.fit(lf_train, item_features=lf_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "lf_hybrid_precision_at_k = precision_at_k(lf_hybrid_model, lf_test, train_interactions=lf_train, \n",
    "                                          item_features=lf_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "lf_hybrid_auc_score = auc_score(lf_hybrid_model, lf_test, train_interactions=lf_train, \n",
    "                                item_features=lf_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_hybrid_predictions = lf_hybrid_model.predict_rank(lf_test,\n",
    "                                                    train_interactions=lf_train,\n",
    "                                                    item_features=lf_item_features,\n",
    "                                                    num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_content_model = LightFM(loss='warp')\n",
    "lf_content_model.fit(lf_train, \n",
    "                     user_features=lf_user_features, \n",
    "                     item_features=lf_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "lf_content_precision_at_k = precision_at_k(lf_content_model, lf_test, train_interactions=lf_train, \n",
    "                                           user_features=lf_user_features,\n",
    "                                           item_features=lf_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "lf_content_auc_score = auc_score(lf_content_model, lf_test, train_interactions=lf_train, \n",
    "                                 user_features=lf_user_features,\n",
    "                                 item_features=lf_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_content_predictions = lf_content_model.predict_rank(lf_test, train_interactions=lf_train, \n",
    "                                                       item_features=lf_item_features, \n",
    "                                                       user_features=lf_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lf_models.pickle', 'wb') as f:\n",
    "    pickle.dump([lf_collab_model, lf_hybrid_model, lf_content_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('lf_models.pickle', 'rb') as f:\n",
    "    lf_collab_model, lf_hybrid_model, lf_content_model = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('lf_results.pickle', 'wb') as f:\n",
    "    pickle.dump([lf_collab_precision_at_k, lf_collab_auc_score, lf_collab_predictions,\n",
    "                lf_hybrid_precision_at_k, lf_hybrid_auc_score, lf_hybrid_predictions,\n",
    "                lf_content_precision_at_k, lf_content_auc_score, lf_content_predictions], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dating Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r dating_data_df\n",
    "%store -r dating_users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "dating_dataset = Dataset()\n",
    "dating_dataset.fit(dating_data_df['Id Usuario'], dating_data_df['Id Match'])\n",
    "dating_dataset.fit_partial(users=dating_users_df['Id Usuario'], items=dating_users_df['Id Usuario'],\n",
    "                    user_features=dating_users_df['Género'], item_features=dating_users_df['Género'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(dating_interactions, dating_weights) = dating_dataset.build_interactions((row['Id Usuario'], row['Id Match'], row['Valoración']) for index, row in dating_data_df.iterrows())\n",
    "dating_item_features = dating_dataset.build_item_features((row['Id Usuario'], [row['Género']]) for index, row in dating_users_df.iterrows())\n",
    "dating_user_features = dating_dataset.build_user_features((row['Id Usuario'], [row['Género']]) for index, row in dating_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dating_train, dating_test = random_train_test_split(dating_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dating_data.pickle', 'wb') as f:\n",
    "    pickle.dump([dating_train, dating_test, dating_item_features, dating_user_features], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('dating_data.pickle', 'rb') as f:\n",
    "    dating_train, dating_test, dating_item_features, dating_user_features = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_collab_model = LightFM(loss='warp')\n",
    "dating_collab_model.fit(dating_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "dating_collab_precision_at_k = precision_at_k(dating_collab_model, dating_test, \n",
    "                                              train_interactions=dating_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "dating_collab_auc_score = auc_score(dating_collab_model, dating_test, \n",
    "                                    train_interactions=dating_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_collab_predictions = dating_collab_model.predict_rank(dating_test, \n",
    "                                                             train_interactions=dating_train, \n",
    "                                                             num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_hybrid_model = LightFM(loss='warp')\n",
    "dating_hybrid_model.fit(dating_train, item_features=dating_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "dating_hybrid_precision_at_k = precision_at_k(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                              item_features=dating_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "dating_hybrid_auc_score = auc_score(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                    item_features=dating_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_hybrid_predictions = dating_hybrid_model.predict_rank(dating_test, \n",
    "                                                             train_interactions=dating_train, \n",
    "                                                             item_features=dating_item_features, \n",
    "                                                             num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_content_model = LightFM(loss='warp')\n",
    "dating_content_model.fit(dating_train, \n",
    "                         user_features=dating_user_features, \n",
    "                         item_features=dating_item_features, \n",
    "                         epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "dating_content_precision_at_k = precision_at_k(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                               user_features=dating_user_features, \n",
    "                                               item_features=dating_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "dating_content_auc_score = auc_score(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                     user_features=dating_user_features, \n",
    "                                     item_features=dating_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_content_predictions = dating_content_model.predict_rank(dating_test, \n",
    "                                                               train_interactions=dating_train, \n",
    "                                                               item_features=dating_item_features, \n",
    "                                                               user_features=dating_user_features, \n",
    "                                                               num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dating_models.pickle', 'wb') as f:\n",
    "    pickle.dump([dating_collab_model, dating_hybrid_model, dating_content_model], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('dating_models.pickle', 'rb') as f:\n",
    "    dating_collab_model, dating_hybrid_model, dating_content_model = pickle.load(f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dating_results.pickle', 'wb') as f:\n",
    "    pickle.dump([dating_collab_precision_at_k, dating_collab_auc_score, dating_collab_predictions,\n",
    "                dating_hybrid_precision_at_k, dating_hybrid_auc_score, dating_hybrid_predictions,\n",
    "                dating_content_precision_at_k, dating_content_auc_score, dating_content_predictions], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
