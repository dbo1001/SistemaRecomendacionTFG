{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recomendación con LightFM\n",
    "En este notebook se obtienen los distintos tipos de modelos (colaborativo, basado en contenido e híbrido) con el conjunto de datos de MovieLens y la librería LightFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# Importar todo lo necesario\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import reciprocal_rank\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del número de hilos del procesador\n",
    "cpu_threads = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r ml_data_df\n",
    "%store -r ml_users_df\n",
    "%store -r ml_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "ml_dataset = Dataset()\n",
    "ml_dataset.fit(ml_data_df['Id Usuario'], ml_data_df['Id Película'])\n",
    "ml_dataset.fit_partial(users=ml_users_df['Id Usuario'], items=ml_items_df['Id Película'],\n",
    "                    user_features=ml_users_df['Género'], item_features=ml_items_df['Título'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(ml_interactions, ml_weights) = ml_dataset.build_interactions((row['Id Usuario'], row['Id Película'], row['Valoración']) for index, row in ml_data_df.iterrows())\n",
    "ml_item_features = ml_dataset.build_item_features((row['Id Película'], [row['Título']]) for index, row in ml_items_df.iterrows())\n",
    "ml_user_features = ml_dataset.build_user_features((row['Id Usuario'], [row['Género']]) for index, row in ml_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divido el conjunto de datos en train y test\n",
    "ml_train, ml_test = random_train_test_split(ml_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los datos en un archivo pickle\n",
    "ml_data_pickle = open('ml_data.pickle', 'wb')\n",
    "pickle.dump([ml_train, ml_test, ml_item_features, ml_user_features], ml_data_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "ml_data_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nml_data_pickle = open('ml_data.pickle', 'rb')\\n[ml_train, ml_test, ml_item_features, ml_user_features] = pickle.load(ml_data_pickle)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los datos\n",
    "\"\"\"\n",
    "ml_data_pickle = open('ml_data.pickle', 'rb')\n",
    "[ml_train, ml_test, ml_item_features, ml_user_features] = pickle.load(ml_data_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1450dd58b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_collab_model = LightFM(loss='warp')\n",
    "ml_collab_model.fit(ml_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "ml_collab_precision_at_k = precision_at_k(ml_collab_model, ml_test, \n",
    "                                          train_interactions=ml_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "ml_collab_auc_score = auc_score(ml_collab_model, ml_test, train_interactions=ml_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo colaborativo\n",
    "ml_collab_recall_at_k = recall_at_k(ml_collab_model, ml_test, train_interactions=ml_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo colaborativo\n",
    "ml_collab_reciprocal_rank = reciprocal_rank(ml_collab_model, ml_test, train_interactions=ml_train, \n",
    "                                            num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_collab_predictions = ml_collab_model.predict_rank(ml_test, \n",
    "                                                     train_interactions=ml_train, \n",
    "                                                     num_threads=cpu_threads,check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1450c632588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_hybrid_model = LightFM(loss='warp')\n",
    "ml_hybrid_model.fit(ml_train, item_features=ml_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "ml_hybrid_precision_at_k = precision_at_k(ml_hybrid_model, ml_test, train_interactions=ml_train, \n",
    "                                          item_features=ml_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "ml_hybrid_auc_score = auc_score(ml_hybrid_model, ml_test, train_interactions=ml_train, \n",
    "                                item_features=ml_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo híbrido\n",
    "ml_hybrid_recall_at_k = recall_at_k(ml_hybrid_model, ml_test, train_interactions=ml_train, item_features=ml_item_features, \n",
    "                                    k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo híbrido\n",
    "ml_hybrid_reciprocal_rank = reciprocal_rank(ml_hybrid_model, ml_test, train_interactions=ml_train, \n",
    "                                            item_features=ml_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_hybrid_predictions = ml_hybrid_model.predict_rank(ml_test, train_interactions=ml_train, \n",
    "                                                     item_features=ml_item_features,  \n",
    "                                                     num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1450c632278>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "ml_content_model = LightFM(loss='warp')\n",
    "ml_content_model.fit(ml_train, user_features=ml_user_features, item_features=ml_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "ml_content_precision_at_k = precision_at_k(ml_content_model, ml_test, train_interactions=ml_train, \n",
    "                                           user_features=ml_user_features, \n",
    "                                           item_features=ml_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "ml_content_auc_score = auc_score(ml_content_model, ml_test, train_interactions=ml_train, \n",
    "                                 user_features=ml_user_features, \n",
    "                                 item_features=ml_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo por contenido\n",
    "ml_content_recall_at_k = recall_at_k(ml_content_model, ml_test, train_interactions=ml_train, user_features=ml_user_features, \n",
    "                                     item_features=ml_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo por contenido\n",
    "ml_content_reciprocal_rank = reciprocal_rank(ml_content_model, ml_test, train_interactions=ml_train, \n",
    "                                             user_features=ml_user_features, item_features=ml_item_features, \n",
    "                                             num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "ml_content_predictions = ml_content_model.predict_rank(ml_test, train_interactions=ml_train, \n",
    "                                                       item_features=ml_item_features, \n",
    "                                                       user_features=ml_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los modelos en un archivo pickle\n",
    "ml_models_pickle = open('ml_models.pickle', 'wb')\n",
    "pickle.dump([ml_collab_model, ml_hybrid_model, ml_content_model], ml_models_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "ml_models_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nml_models_pickle = open('ml_models.pickle', 'rb')\\n[ml_collab_model, ml_hybrid_model, ml_content_model] = pickle.load(ml_models_pickle)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los modelos\n",
    "\"\"\"\n",
    "ml_models_pickle = open('ml_models.pickle', 'rb')\n",
    "[ml_collab_model, ml_hybrid_model, ml_content_model] = pickle.load(ml_models_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo los resultados en un archivo pickle\n",
    "ml_results_pickle = open('ml_results.pickle', 'wb')\n",
    "pickle.dump([ml_collab_precision_at_k, ml_collab_auc_score, ml_collab_recall_at_k, ml_collab_reciprocal_rank, ml_collab_predictions, \n",
    "             ml_hybrid_precision_at_k, ml_hybrid_auc_score, ml_hybrid_recall_at_k, ml_hybrid_reciprocal_rank, ml_hybrid_predictions,\n",
    "             ml_content_precision_at_k, ml_content_auc_score, ml_content_recall_at_k, ml_content_reciprocal_rank, ml_content_predictions], \n",
    "            ml_results_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "ml_results_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r anime_data_df\n",
    "%store -r anime_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "anime_dataset = Dataset()\n",
    "anime_dataset.fit(anime_data_df['Id Usuario'], anime_data_df['Id Anime'])\n",
    "anime_dataset.fit_partial(items=anime_items_df['Id Anime'], item_features=anime_items_df['Título'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(anime_interactions, anime_weights) = anime_dataset.build_interactions((row['Id Usuario'], row['Id Anime'], row['Valoración']) for index, row in anime_data_df.iterrows())\n",
    "anime_item_features = anime_dataset.build_item_features((row['Id Anime'], [row['Título']]) for index, row in anime_items_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divido el conjunto de datos en train y test\n",
    "anime_train, anime_test = random_train_test_split(anime_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo los datos en un archivo pickle\n",
    "anime_data_pickle = open('anime_data.pickle', 'wb')\n",
    "pickle.dump([anime_train, anime_test, anime_item_features], anime_data_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "anime_data_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nanime_data_pickle = open('anime_data.pickle', 'rb')\\n[anime_train, anime_test, anime_item_features, anime_user_features] = pickle.load(anime_data_pickle)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los datos\n",
    "\"\"\"\n",
    "anime_data_pickle = open('anime_data.pickle', 'rb')\n",
    "[anime_train, anime_test, anime_item_features, anime_user_features] = pickle.load(anime_data_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1450c97a518>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "anime_collab_model = LightFM(loss='warp')\n",
    "anime_collab_model.fit(anime_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "anime_collab_precision_at_k = precision_at_k(anime_collab_model, anime_test, \n",
    "                                             train_interactions=anime_train, k=10, num_threads=cpu_threads, \n",
    "                                             check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "anime_collab_auc_score = auc_score(anime_collab_model, anime_test, \n",
    "                                   train_interactions=anime_train, num_threads=cpu_threads, check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo colaborativo\n",
    "anime_collab_recall_at_k = recall_at_k(anime_collab_model, anime_test, \n",
    "                                       train_interactions=anime_train, k=10, num_threads=cpu_threads, \n",
    "                                       check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo colaborativo\n",
    "anime_collab_reciprocal_rank = reciprocal_rank(anime_collab_model, anime_test, train_interactions=anime_train, \n",
    "                                               num_threads=cpu_threads, check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "anime_collab_predictions = anime_collab_model.predict_rank(anime_test, \n",
    "                                                           train_interactions=anime_train, \n",
    "                                                           num_threads=cpu_threads,\n",
    "                                                           check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x14516a862e8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "anime_hybrid_model = LightFM(loss='warp')\n",
    "anime_hybrid_model.fit(anime_interactions, item_features=anime_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "anime_hybrid_precision_at_k = precision_at_k(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                             item_features=anime_item_features, k=10, num_threads=cpu_threads, \n",
    "                                             check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "anime_hybrid_auc_score = auc_score(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                item_features=anime_item_features, num_threads=cpu_threads, check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo híbrido\n",
    "anime_hybrid_recall_at_k = recall_at_k(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                       item_features=anime_item_features, k=10, num_threads=cpu_threads, \n",
    "                                       check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo híbrido\n",
    "anime_hybrid_reciprocal_rank = reciprocal_rank(anime_hybrid_model, anime_test, train_interactions=anime_train, \n",
    "                                               item_features=anime_item_features, num_threads=cpu_threads, \n",
    "                                               check_intersections=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "anime_hybrid_predictions = anime_hybrid_model.predict_rank(anime_test, \n",
    "                                                           train_interactions=anime_train, \n",
    "                                                           item_features=anime_item_features, \n",
    "                                                           num_threads=cpu_threads,\n",
    "                                                           check_intersections=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los modelos en un archivo pickle\n",
    "anime_models_pickle = open('anime_models.pickle', 'wb')\n",
    "pickle.dump([anime_collab_model, anime_hybrid_model], anime_models_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "anime_models_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nanime_models_pickle = open('anime_models.pickle', 'rb')\\n[anime_collab_model, anime_hybrid_model] = pickle.load(anime_models_pickle)\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los modelos\n",
    "\"\"\"\n",
    "anime_models_pickle = open('anime_models.pickle', 'rb')\n",
    "[anime_collab_model, anime_hybrid_model] = pickle.load(anime_models_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los resultados en un archivo pickle\n",
    "anime_results_pickle = open('anime_results.pickle', 'wb')\n",
    "pickle.dump([anime_collab_precision_at_k, anime_collab_auc_score, anime_collab_recall_at_k, anime_collab_reciprocal_rank, anime_collab_predictions, \n",
    "             anime_hybrid_precision_at_k, anime_hybrid_auc_score, anime_hybrid_recall_at_k, anime_hybrid_reciprocal_rank, anime_hybrid_predictions],\n",
    "            anime_results_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "anime_results_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book-Crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r bc_data_df\n",
    "%store -r bc_users_df\n",
    "%store -r bc_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "bc_dataset = Dataset()\n",
    "bc_dataset.fit(bc_data_df['Id Usuario'], bc_data_df['ISBN'])\n",
    "bc_dataset.fit_partial(users=bc_users_df['Id Usuario'], items=bc_items_df['ISBN'],\n",
    "                    user_features=bc_users_df['Edad'], item_features=bc_items_df['Título'])\n",
    "\n",
    "#num_users, num_items = bc_dataset.interactions_shape()\n",
    "#print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "# Obtención de las matrices\n",
    "(bc_interactions, bc_weights) = bc_dataset.build_interactions((row['Id Usuario'], row['ISBN'], row['Valoración']) for index, row in bc_data_df.iterrows())\n",
    "bc_item_features = bc_dataset.build_item_features((row['ISBN'], [row['Título']]) for index, row in bc_items_df.iterrows())\n",
    "bc_user_features = bc_dataset.build_user_features((row['Id Usuario'], [row['Edad']]) for index, row in bc_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divido el conjunto de datos en train y test\n",
    "bc_train, bc_test = random_train_test_split(bc_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los datos en un archivo pickle\n",
    "bc_data_pickle = open('bc_data.pickle', 'wb')\n",
    "pickle.dump([bc_train, bc_test, bc_item_features, bc_user_features], bc_data_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "bc_data_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbc_data_pickle = open('bc_data.pickle', 'rb')\\n[bc_train, bc_test, bc_item_features, bc_user_features] = pickle.load(bc_data_pickle)\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los datos\n",
    "\"\"\"\n",
    "bc_data_pickle = open('bc_data.pickle', 'rb')\n",
    "[bc_train, bc_test, bc_item_features, bc_user_features] = pickle.load(bc_data_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x145393c0e80>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_collab_model = LightFM(loss='warp')\n",
    "bc_collab_model.fit(bc_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "bc_collab_precision_at_k = precision_at_k(bc_collab_model, bc_test, \n",
    "                                          train_interactions=bc_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "bc_collab_auc_score = auc_score(bc_collab_model, bc_test, \n",
    "                                train_interactions=bc_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo colaborativo\n",
    "bc_collab_recall_at_k = recall_at_k(bc_collab_model, bc_test, train_interactions=bc_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo colaborativo\n",
    "bc_collab_reciprocal_rank = reciprocal_rank(bc_collab_model, bc_test, train_interactions=bc_train, \n",
    "                                            num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_collab_predictions = bc_collab_model.predict_rank(bc_test, \n",
    "                                                     train_interactions=bc_train, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1452839b668>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_hybrid_model = LightFM(loss='warp')\n",
    "bc_hybrid_model.fit(bc_train, item_features=bc_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "bc_hybrid_precision_at_k = precision_at_k(bc_hybrid_model, bc_test, train_interactions=bc_train, \n",
    "                                          item_features=bc_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "bc_hybrid_auc_score = auc_score(bc_hybrid_model, bc_test, train_interactions=bc_train, \n",
    "                                item_features=bc_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo híbrido\n",
    "bc_hybrid_recall_at_k = recall_at_k(bc_hybrid_model, bc_test, train_interactions=bc_train, item_features=bc_item_features, \n",
    "                                    k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo híbrido\n",
    "bc_hybrid_reciprocal_rank = reciprocal_rank(bc_hybrid_model, bc_test, train_interactions=bc_train, \n",
    "                                            item_features=bc_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_hybrid_predictions = bc_hybrid_model.predict_rank(bc_test, \n",
    "                                                     train_interactions=bc_train, \n",
    "                                                     item_features=bc_item_features, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x14516a86eb8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "bc_content_model = LightFM(loss='warp')\n",
    "bc_content_model.fit(bc_train, \n",
    "                     user_features=bc_user_features, \n",
    "                     item_features=bc_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "bc_content_precision_at_k = precision_at_k(bc_content_model, bc_test, train_interactions=bc_train, \n",
    "                                           user_features=bc_user_features,\n",
    "                                           item_features=bc_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "bc_content_auc_score = auc_score(bc_content_model, bc_test, train_interactions=bc_train, \n",
    "                                 user_features=bc_user_features,\n",
    "                                 item_features=bc_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo por contenido\n",
    "bc_content_recall_at_k = recall_at_k(bc_content_model, bc_test, train_interactions=bc_train, user_features=bc_user_features, \n",
    "                                     item_features=bc_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo por contenido\n",
    "bc_content_reciprocal_rank = reciprocal_rank(bc_content_model, bc_test, train_interactions=bc_train, \n",
    "                                             user_features=bc_user_features, item_features=bc_item_features, \n",
    "                                             num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "bc_content_predictions = bc_content_model.predict_rank(bc_test, train_interactions=bc_train, \n",
    "                                                       item_features=bc_item_features, \n",
    "                                                       user_features=bc_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los modelos en un archivo pickle\n",
    "bc_models_pickle = open('bc_models.pickle', 'wb')\n",
    "pickle.dump([bc_collab_model, bc_hybrid_model, bc_content_model], bc_models_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "bc_models_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbc_models_pickle = open('bc_models.pickle', 'rb')\\n[bc_collab_model, bc_hybrid_model, bc_content_model] = pickle.load(bc_models_pickle)\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recojo los modelos\n",
    "\"\"\"\n",
    "bc_models_pickle = open('bc_models.pickle', 'rb')\n",
    "[bc_collab_model, bc_hybrid_model, bc_content_model] = pickle.load(bc_models_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los resultados en un archivo pickle\n",
    "bc_results_pickle = open('bc_results.pickle', 'wb')\n",
    "pickle.dump([bc_collab_precision_at_k, bc_collab_auc_score, bc_collab_recall_at_k, bc_collab_reciprocal_rank, bc_collab_predictions, \n",
    "             bc_hybrid_precision_at_k, bc_hybrid_auc_score, bc_hybrid_recall_at_k, bc_hybrid_reciprocal_rank, bc_hybrid_predictions,\n",
    "             bc_content_precision_at_k, bc_content_auc_score, bc_content_recall_at_k, bc_content_reciprocal_rank, bc_content_predictions], \n",
    "            bc_results_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "bc_results_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LastFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r lf_data_df\n",
    "%store -r lf_users_df\n",
    "%store -r lf_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "lf_dataset = Dataset()\n",
    "lf_dataset.fit(lf_data_df['Id Usuario'], lf_data_df['Id Artista'])\n",
    "lf_dataset.fit_partial(users=lf_users_df['Id Usuario'], items=lf_items_df['Id Artista'],\n",
    "                    user_features=lf_users_df['Id Amigo'], item_features=lf_items_df['Nombre'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(lf_interactions, lf_weights) = lf_dataset.build_interactions((row['Id Usuario'], row['Id Artista'], row['Veces escuchado']) for index, row in lf_data_df.iterrows())\n",
    "lf_item_features = lf_dataset.build_item_features((row['Id Artista'], [row['Nombre']]) for index, row in lf_items_df.iterrows())\n",
    "lf_user_features = lf_dataset.build_user_features((row['Id Usuario'], [row['Id Amigo']]) for index, row in lf_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divido el conjunto de datos en train y test\n",
    "lf_train, lf_test = random_train_test_split(lf_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los datos en un archivo pickle\n",
    "lf_data_pickle = open('lf_data.pickle', 'wb')\n",
    "pickle.dump([lf_train, lf_test, lf_item_features, lf_user_features], lf_data_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "lf_data_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recojo los datos\n",
    "\"\"\"\n",
    "lf_data_pickle = open('lf_data.pickle', 'rb')\n",
    "[lf_train, lf_test, lf_item_features, lf_user_features] = pickle.load(lf_data_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_collab_model = LightFM(loss='warp')\n",
    "lf_collab_model.fit(lf_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "lf_collab_precision_at_k = precision_at_k(lf_collab_model, lf_test, \n",
    "                                          train_interactions=lf_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "lf_collab_auc_score = auc_score(lf_collab_model, lf_test, \n",
    "                                train_interactions=lf_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo colaborativo\n",
    "lf_collab_recall_at_k = recall_at_k(lf_collab_model, lf_test, train_interactions=lf_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo colaborativo\n",
    "lf_collab_reciprocal_rank = reciprocal_rank(lf_collab_model, lf_test, train_interactions=lf_train, \n",
    "                                            num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_collab_predictions = lf_collab_model.predict_rank(lf_test, \n",
    "                                                     train_interactions=lf_train, \n",
    "                                                     num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_hybrid_model = LightFM(loss='warp')\n",
    "lf_hybrid_model.fit(lf_train, item_features=lf_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "lf_hybrid_precision_at_k = precision_at_k(lf_hybrid_model, lf_test, train_interactions=lf_train, \n",
    "                                          item_features=lf_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "lf_hybrid_auc_score = auc_score(lf_hybrid_model, lf_test, train_interactions=lf_train, \n",
    "                                item_features=lf_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo híbrido\n",
    "lf_hybrid_recall_at_k = recall_at_k(lf_hybrid_model, lf_test, train_interactions=lf_train, item_features=lf_item_features, \n",
    "                                    k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo híbrido\n",
    "lf_hybrid_reciprocal_rank = reciprocal_rank(lf_hybrid_model, lf_test, train_interactions=lf_train, \n",
    "                                            item_features=lf_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_hybrid_predictions = lf_hybrid_model.predict_rank(lf_test,\n",
    "                                                    train_interactions=lf_train,\n",
    "                                                    item_features=lf_item_features,\n",
    "                                                    num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "lf_content_model = LightFM(loss='warp')\n",
    "lf_content_model.fit(lf_train, \n",
    "                     user_features=lf_user_features, \n",
    "                     item_features=lf_item_features, \n",
    "                     epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "lf_content_precision_at_k = precision_at_k(lf_content_model, lf_test, train_interactions=lf_train, \n",
    "                                           user_features=lf_user_features,\n",
    "                                           item_features=lf_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "lf_content_auc_score = auc_score(lf_content_model, lf_test, train_interactions=lf_train, \n",
    "                                 user_features=lf_user_features,\n",
    "                                 item_features=lf_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo por contenido\n",
    "lf_content_recall_at_k = recall_at_k(lf_content_model, lf_test, train_interactions=lf_train, user_features=lf_user_features, \n",
    "                                     item_features=lf_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo por contenido\n",
    "lf_content_reciprocal_rank = reciprocal_rank(lf_content_model, lf_test, train_interactions=lf_train, \n",
    "                                             user_features=lf_user_features, item_features=lf_item_features, \n",
    "                                             num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "lf_content_predictions = lf_content_model.predict_rank(lf_test, train_interactions=lf_train, \n",
    "                                                       item_features=lf_item_features, \n",
    "                                                       user_features=lf_user_features, \n",
    "                                                       num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los modelos en un archivo pickle\n",
    "lf_models_pickle = open('lf_models.pickle', 'wb')\n",
    "pickle.dump([lf_collab_model, lf_hybrid_model, lf_content_model], lf_models_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "lf_models_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recojo los modelos\n",
    "\"\"\"\n",
    "lf_models_pickle = open('lf_models.pickle', 'rb')\n",
    "[lf_collab_model, lf_hybrid_model, lf_content_model] = pickle.load(lf_models_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los resultados en un archivo pickle\n",
    "lf_results_pickle = open('lf_results.pickle', 'wb')\n",
    "pickle.dump([lf_collab_precision_at_k, lf_collab_auc_score, lf_collab_recall_at_k, lf_collab_reciprocal_rank, lf_collab_predictions, \n",
    "             lf_hybrid_precision_at_k, lf_hybrid_auc_score, lf_hybrid_recall_at_k, lf_hybrid_reciprocal_rank, lf_hybrid_predictions,\n",
    "             lf_content_precision_at_k, lf_content_auc_score, lf_content_recall_at_k, lf_content_reciprocal_rank, lf_content_predictions], \n",
    "            lf_results_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "lf_results_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dating Agency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención los dataframes previamente creados\n",
    "%store -r dating_data_df\n",
    "%store -r dating_users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "dating_dataset = Dataset()\n",
    "dating_dataset.fit(dating_data_df['Id Usuario'], dating_data_df['Id Match'])\n",
    "dating_dataset.fit_partial(users=dating_users_df['Id Usuario'], items=dating_users_df['Id Usuario'],\n",
    "                    user_features=dating_users_df['Género'], item_features=dating_users_df['Género'])\n",
    "\n",
    "# Obtención de las matrices\n",
    "(dating_interactions, dating_weights) = dating_dataset.build_interactions((row['Id Usuario'], row['Id Match'], row['Valoración']) for index, row in dating_data_df.iterrows())\n",
    "dating_item_features = dating_dataset.build_item_features((row['Id Usuario'], [row['Género']]) for index, row in dating_users_df.iterrows())\n",
    "dating_user_features = dating_dataset.build_user_features((row['Id Usuario'], [row['Género']]) for index, row in dating_users_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divido el conjunto de datos en train y test\n",
    "dating_train, dating_test = random_train_test_split(dating_interactions, test_percentage=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los datos en un archivo pickle\n",
    "dating_data_pickle = open('dating_data.pickle', 'wb')\n",
    "pickle.dump([dating_train, dating_test, dating_item_features, dating_user_features], \n",
    "            dating_data_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "dating_data_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recojo los datos\n",
    "\"\"\"\n",
    "dating_data_pickle = open('dating_data.pickle', 'rb')\n",
    "[dating_train, dating_test, dating_item_features, dating_user_features] = pickle.load(dating_data_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_collab_model = LightFM(loss='warp')\n",
    "dating_collab_model.fit(dating_train, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo colaborativo\n",
    "dating_collab_precision_at_k = precision_at_k(dating_collab_model, dating_test, \n",
    "                                              train_interactions=dating_train, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo colaborativo\n",
    "dating_collab_auc_score = auc_score(dating_collab_model, dating_test, \n",
    "                                    train_interactions=dating_train, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo colaborativo\n",
    "dating_collab_recall_at_k = recall_at_k(dating_collab_model, dating_test, train_interactions=dating_train, \n",
    "                                        k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo colaborativo\n",
    "dating_collab_reciprocal_rank = reciprocal_rank(dating_collab_model, dating_test, train_interactions=dating_train, \n",
    "                                                num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_collab_predictions = dating_collab_model.predict_rank(dating_test, \n",
    "                                                             train_interactions=dating_train, \n",
    "                                                             num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_hybrid_model = LightFM(loss='warp')\n",
    "dating_hybrid_model.fit(dating_train, item_features=dating_item_features, epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo híbrido\n",
    "dating_hybrid_precision_at_k = precision_at_k(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                              item_features=dating_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo híbrido\n",
    "dating_hybrid_auc_score = auc_score(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                    item_features=dating_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo híbrido\n",
    "dating_hybrid_recall_at_k = recall_at_k(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                        item_features=dating_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo híbrido\n",
    "dating_hybrid_reciprocal_rank = reciprocal_rank(dating_hybrid_model, dating_test, train_interactions=dating_train, \n",
    "                                                item_features=dating_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_hybrid_predictions = dating_hybrid_model.predict_rank(dating_test, \n",
    "                                                             train_interactions=dating_train, \n",
    "                                                             item_features=dating_item_features, \n",
    "                                                             num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención el modelo y entrenamiento\n",
    "dating_content_model = LightFM(loss='warp')\n",
    "dating_content_model.fit(dating_train, \n",
    "                         user_features=dating_user_features, \n",
    "                         item_features=dating_item_features, \n",
    "                         epochs=30, num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de la precisión k con el modelo por contenido\n",
    "dating_content_precision_at_k = precision_at_k(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                               user_features=dating_user_features, \n",
    "                                               item_features=dating_item_features, k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del AUC score con el modelo por contenido\n",
    "dating_content_auc_score = auc_score(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                     user_features=dating_user_features, \n",
    "                                     item_features=dating_item_features, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del recall k con el modelo por contenido\n",
    "dating_content_recall_at_k = recall_at_k(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                         user_features=dating_user_features, item_features=dating_item_features, \n",
    "                                         k=10, num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del reciprocal rank con el modelo por contenido\n",
    "dating_content_reciprocal_rank = reciprocal_rank(dating_content_model, dating_test, train_interactions=dating_train, \n",
    "                                                 user_features=dating_user_features, item_features=dating_item_features, \n",
    "                                                 num_threads=cpu_threads).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del ranking para todos los usuarios/items\n",
    "dating_content_predictions = dating_content_model.predict_rank(dating_test, \n",
    "                                                               train_interactions=dating_train, \n",
    "                                                               item_features=dating_item_features, \n",
    "                                                               user_features=dating_user_features, \n",
    "                                                               num_threads=cpu_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Guardado de los modelos y resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los modelos en un archivo pickle\n",
    "dating_models_pickle = open('dating_models.pickle', 'wb')\n",
    "pickle.dump([dating_collab_model, dating_hybrid_model, dating_content_model], dating_models_pickle, \n",
    "            protocol=pickle.HIGHEST_PROTOCOL)\n",
    "dating_models_pickle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recojo los modelos\n",
    "\"\"\"\n",
    "dating_models_pickle = open('dating_models.pickle', 'rb')\n",
    "[dating_collab_model, dating_hybrid_model, dating_content_model] = pickle.load(dating_models_pickle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Guardo los resultados en un archivo pickle\n",
    "dating_results_pickle = open('dating_results.pickle', 'wb')\n",
    "pickle.dump([dating_collab_precision_at_k, dating_collab_auc_score, dating_collab_recall_at_k, dating_collab_reciprocal_rank, dating_collab_predictions, \n",
    "             dating_hybrid_precision_at_k, dating_hybrid_auc_score, dating_hybrid_recall_at_k, dating_hybrid_reciprocal_rank, dating_hybrid_predictions,\n",
    "             dating_content_precision_at_k, dating_content_auc_score, dating_content_recall_at_k, dating_content_reciprocal_rank, dating_content_predictions], \n",
    "            dating_results_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "dating_results_pickle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
