{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salida de resultados   \n",
    "En este notebook se muestran los resultados obtenidos por los distintos modelos con LightFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importar todo lo necesario\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del path del pickle\n",
    "ml_pickle_path = os.path.join(os.path.expanduser('~'), 'Downloads', 'datos_intermedios', 'ml_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los resultados\n",
    "ml_results_pickle = open(ml_pickle_path, 'rb')\n",
    "[ml_collab_precision_at_k, ml_collab_auc_score, ml_collab_recall_at_k, ml_collab_reciprocal_rank, ml_collab_predictions,\n",
    "ml_hybrid_precision_at_k, ml_hybrid_auc_score, ml_hybrid_recall_at_k, ml_hybrid_reciprocal_rank, ml_hybrid_predictions, \n",
    "ml_content_precision_at_k, ml_content_auc_score, ml_content_recall_at_k, ml_content_reciprocal_rank, ml_content_predictions] = pickle.load(ml_results_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión k modelo colaborativo: 0.3335\n",
      "AUC score modelo colaborativo: 0.9326\n",
      "Recall k modelo colaborativo: 0.2135\n",
      "Reciprocal rank modelo colaborativo: 0.6419 \n",
      "\n",
      "Precisión k modelo híbrido: 0.3346\n",
      "AUC score modelo híbrido: 0.9336\n",
      "Recall k modelo híbrido: 0.2143\n",
      "Reciprocal rank modelo híbrido: 0.6496 \n",
      "\n",
      "Precisión k modelo por contenido: 0.3074\n",
      "AUC score modelo por contenido: 0.9154\n",
      "Recall k modelo por contenido: 0.1912\n",
      "Reciprocal rank modelo por contenido: 0.5963\n"
     ]
    }
   ],
   "source": [
    "# Salida de los resultados\n",
    "print('Precisión k modelo colaborativo: %.4f' % ml_collab_precision_at_k)\n",
    "print('AUC score modelo colaborativo: %.4f' % ml_collab_auc_score)\n",
    "print('Recall k modelo colaborativo: %.4f' % ml_collab_recall_at_k)\n",
    "print('Reciprocal rank modelo colaborativo: %.4f \\n' % ml_collab_reciprocal_rank)\n",
    "print('Precisión k modelo híbrido: %.4f' % ml_hybrid_precision_at_k)\n",
    "print('AUC score modelo híbrido: %.4f' % ml_hybrid_auc_score)\n",
    "print('Recall k modelo híbrido: %.4f' % ml_hybrid_recall_at_k)\n",
    "print('Reciprocal rank modelo híbrido: %.4f \\n' % ml_hybrid_reciprocal_rank)\n",
    "print('Precisión k modelo por contenido: %.4f' % ml_content_precision_at_k)\n",
    "print('AUC score modelo por contenido: %.4f' % ml_content_auc_score)\n",
    "print('Recall k modelo por contenido: %.4f' % ml_content_recall_at_k)\n",
    "print('Reciprocal rank modelo por contenido: %.4f' % ml_content_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del path del pickle\n",
    "anime_pickle_path = os.path.join(os.path.expanduser('~'), 'Downloads', 'datos_intermedios', 'anime_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los resultados\n",
    "anime_results_pickle = open(anime_pickle_path, 'rb')\n",
    "[anime_collab_precision_at_k, anime_collab_auc_score, anime_collab_recall_at_k, anime_collab_reciprocal_rank, anime_collab_predictions,\n",
    "anime_hybrid_precision_at_k, anime_hybrid_auc_score, anime_hybrid_recall_at_k, anime_hybrid_reciprocal_rank, anime_hybrid_predictions] = pickle.load(anime_results_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión k modelo colaborativo: 0.2626\n",
      "AUC score modelo colaborativo: 0.9808\n",
      "Recall k modelo colaborativo: 0.1766\n",
      "Reciprocal rank modelo colaborativo: 0.5429 \n",
      "\n",
      "Precisión k modelo híbrido: 0.2713\n",
      "AUC score modelo híbrido: 0.9844\n",
      "Recall k modelo híbrido: 0.1940\n",
      "Reciprocal rank modelo híbrido: 0.5592\n"
     ]
    }
   ],
   "source": [
    "# Salida de los resultados\n",
    "print('Precisión k modelo colaborativo: %.4f' % anime_collab_precision_at_k)\n",
    "print('AUC score modelo colaborativo: %.4f' % anime_collab_auc_score)\n",
    "print('Recall k modelo colaborativo: %.4f' % anime_collab_recall_at_k)\n",
    "print('Reciprocal rank modelo colaborativo: %.4f \\n' % anime_collab_reciprocal_rank)\n",
    "print('Precisión k modelo híbrido: %.4f' % anime_hybrid_precision_at_k)\n",
    "print('AUC score modelo híbrido: %.4f' % anime_hybrid_auc_score)\n",
    "print('Recall k modelo híbrido: %.4f' % anime_hybrid_recall_at_k)\n",
    "print('Reciprocal rank modelo híbrido: %.4f' % anime_hybrid_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book-Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del path del pickle\n",
    "bc_pickle_path = os.path.join(os.path.expanduser('~'), 'Google Drive', 'GitHub', 'SistemaRecomendacionTFG', \n",
    "                              'src', 'modelo', 'bc_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los resultados\n",
    "bc_results_pickle = open(bc_pickle_path, 'rb')\n",
    "[bc_collab_precision_at_k, bc_collab_auc_score, bc_collab_recall_at_k, bc_collab_reciprocal_rank, bc_collab_predictions,\n",
    "bc_hybrid_precision_at_k, bc_hybrid_auc_score, bc_hybrid_recall_at_k, bc_hybrid_reciprocal_rank, bc_hybrid_predictions, \n",
    "bc_content_precision_at_k, bc_content_auc_score, bc_content_recall_at_k, bc_content_reciprocal_rank, bc_content_predictions] = pickle.load(bc_results_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión k modelo colaborativo: 0.0043\n",
      "AUC score modelo colaborativo: 0.7442\n",
      "Recall k modelo colaborativo: 0.0141\n",
      "Reciprocal rank modelo colaborativo: 0.0213 \n",
      "\n",
      "Precisión k modelo híbrido: 0.0047\n",
      "AUC score modelo híbrido: 0.7559\n",
      "Recall k modelo híbrido: 0.0150\n",
      "Reciprocal rank modelo híbrido: 0.0223 \n",
      "\n",
      "Precisión k modelo por contenido: 0.0039\n",
      "AUC score modelo por contenido: 0.7218\n",
      "Recall k modelo por contenido: 0.0128\n",
      "Reciprocal rank modelo por contenido: 0.0191\n"
     ]
    }
   ],
   "source": [
    "# Salida de los resultados\n",
    "print('Precisión k modelo colaborativo: %.4f' % bc_collab_precision_at_k)\n",
    "print('AUC score modelo colaborativo: %.4f' % bc_collab_auc_score)\n",
    "print('Recall k modelo colaborativo: %.4f' % bc_collab_recall_at_k)\n",
    "print('Reciprocal rank modelo colaborativo: %.4f \\n' % bc_collab_reciprocal_rank)\n",
    "print('Precisión k modelo híbrido: %.4f' % bc_hybrid_precision_at_k)\n",
    "print('AUC score modelo híbrido: %.4f' % bc_hybrid_auc_score)\n",
    "print('Recall k modelo híbrido: %.4f' % bc_hybrid_recall_at_k)\n",
    "print('Reciprocal rank modelo híbrido: %.4f \\n' % bc_hybrid_reciprocal_rank)\n",
    "print('Precisión k modelo por contenido: %.4f' % bc_content_precision_at_k)\n",
    "print('AUC score modelo por contenido: %.4f' % bc_content_auc_score)\n",
    "print('Recall k modelo por contenido: %.4f' % bc_content_recall_at_k)\n",
    "print('Reciprocal rank modelo por contenido: %.4f' % bc_content_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del path del pickle\n",
    "lf_pickle_path = os.path.join(os.path.expanduser('~'), 'Downloads', 'datos_intermedios', 'lf_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los resultados\n",
    "lf_results_pickle = open(lf_pickle_path, 'rb')\n",
    "[lf_collab_precision_at_k, lf_collab_auc_score, lf_collab_recall_at_k, lf_collab_reciprocal_rank, lf_collab_predictions,\n",
    "lf_hybrid_precision_at_k, lf_hybrid_auc_score, lf_hybrid_recall_at_k, lf_hybrid_reciprocal_rank, lf_hybrid_predictions, \n",
    "lf_content_precision_at_k, lf_content_auc_score, lf_content_recall_at_k, lf_content_reciprocal_rank, lf_content_predictions] = pickle.load(lf_results_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión k modelo colaborativo: 0.1418\n",
      "AUC score modelo colaborativo: 0.8694\n",
      "Recall k modelo colaborativo: 0.1467\n",
      "Reciprocal rank modelo colaborativo: 0.4121 \n",
      "\n",
      "Precisión k modelo híbrido: 0.1429\n",
      "AUC score modelo híbrido: 0.8706\n",
      "Recall k modelo híbrido: 0.1485\n",
      "Reciprocal rank modelo híbrido: 0.4117 \n",
      "\n",
      "Precisión k modelo por contenido: 0.1338\n",
      "AUC score modelo por contenido: 0.8627\n",
      "Recall k modelo por contenido: 0.1379\n",
      "Reciprocal rank modelo por contenido: 0.3870\n"
     ]
    }
   ],
   "source": [
    "# Salida de los resultados\n",
    "print('Precisión k modelo colaborativo: %.4f' % lf_collab_precision_at_k)\n",
    "print('AUC score modelo colaborativo: %.4f' % lf_collab_auc_score)\n",
    "print('Recall k modelo colaborativo: %.4f' % lf_collab_recall_at_k)\n",
    "print('Reciprocal rank modelo colaborativo: %.4f \\n' % lf_collab_reciprocal_rank)\n",
    "print('Precisión k modelo híbrido: %.4f' % lf_hybrid_precision_at_k)\n",
    "print('AUC score modelo híbrido: %.4f' % lf_hybrid_auc_score)\n",
    "print('Recall k modelo híbrido: %.4f' % lf_hybrid_recall_at_k)\n",
    "print('Reciprocal rank modelo híbrido: %.4f \\n' % lf_hybrid_reciprocal_rank)\n",
    "print('Precisión k modelo por contenido: %.4f' % lf_content_precision_at_k)\n",
    "print('AUC score modelo por contenido: %.4f' % lf_content_auc_score)\n",
    "print('Recall k modelo por contenido: %.4f' % lf_content_recall_at_k)\n",
    "print('Reciprocal rank modelo por contenido: %.4f' % lf_content_reciprocal_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dating Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del path del pickle\n",
    "dating_pickle_path = os.path.join(os.path.expanduser('~'), 'Downloads', 'datos_intermedios', 'dating_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los resultados\n",
    "dating_results_pickle = open(dating_pickle_path, 'rb')\n",
    "[dating_collab_precision_at_k, dating_collab_auc_score, dating_collab_recall_at_k, dating_collab_reciprocal_rank, dating_collab_predictions,\n",
    "dating_hybrid_precision_at_k, dating_hybrid_auc_score, dating_hybrid_recall_at_k, dating_hybrid_reciprocal_rank, dating_hybrid_predictions, \n",
    "dating_content_precision_at_k, dating_content_auc_score, dating_content_recall_at_k, dating_content_reciprocal_rank, dating_content_predictions] = pickle.load(dating_results_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión k modelo colaborativo: 0.1372\n",
      "AUC score modelo colaborativo: 0.9818\n",
      "Recall k modelo colaborativo: 0.0867\n",
      "Reciprocal rank modelo colaborativo: 0.3885 \n",
      "\n",
      "Precisión k modelo híbrido: 0.1284\n",
      "AUC score modelo híbrido: 0.9774\n",
      "Recall k modelo híbrido: 0.0791\n",
      "Reciprocal rank modelo híbrido: 0.3600 \n",
      "\n",
      "Precisión k modelo por contenido: 0.0786\n",
      "AUC score modelo por contenido: 0.9683\n",
      "Recall k modelo por contenido: 0.0517\n",
      "Reciprocal rank modelo por contenido: 0.2522\n"
     ]
    }
   ],
   "source": [
    "# Salida de los resultados\n",
    "print('Precisión k modelo colaborativo: %.4f' % dating_collab_precision_at_k)\n",
    "print('AUC score modelo colaborativo: %.4f' % dating_collab_auc_score)\n",
    "print('Recall k modelo colaborativo: %.4f' % dating_collab_recall_at_k)\n",
    "print('Reciprocal rank modelo colaborativo: %.4f \\n' % dating_collab_reciprocal_rank)\n",
    "print('Precisión k modelo híbrido: %.4f' % dating_hybrid_precision_at_k)\n",
    "print('AUC score modelo híbrido: %.4f' % dating_hybrid_auc_score)\n",
    "print('Recall k modelo híbrido: %.4f' % dating_hybrid_recall_at_k)\n",
    "print('Reciprocal rank modelo híbrido: %.4f \\n' % dating_hybrid_reciprocal_rank)\n",
    "print('Precisión k modelo por contenido: %.4f' % dating_content_precision_at_k)\n",
    "print('AUC score modelo por contenido: %.4f' % dating_content_auc_score)\n",
    "print('Recall k modelo por contenido: %.4f' % dating_content_recall_at_k)\n",
    "print('Reciprocal rank modelo por contenido: %.4f' % dating_content_reciprocal_rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
