{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistemas de recomendación con LightFM\n",
    "En este notebook se obtienen los distintos tipos de modelos (colaborativo, basado en contenido e híbrido) con el conjunto de datos de MovieLens y la librería LightFM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# Importar todo lo necesario\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pequeña función para ver las recomendaciones\n",
    "def sample_recommendation(model, data, user_ids, items_df):\n",
    "    n_users, n_items = data.shape\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        known_positives = items_df['Título'][data.tocsr()[user_id].indices]\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        top_items = items_df['Título'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"    Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "            \n",
    "        print(\"    Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"         %s\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del dataframe de datos\n",
    "ml_data_df = pd.read_csv('data/movielens/ml_data.csv', delim_whitespace=True, names=['Id Usuario','Id Película','Valoración','Fecha'])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#data_df\n",
    "\n",
    "# Obtención del dataframe de usuarios\n",
    "ml_user_df = pd.read_csv('data/movielens/user.csv', sep='|', names=['Id Usuario', 'Edad', 'Género', 'Ocupación', 'Código Postal'])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#user_df\n",
    "\n",
    "# Obtención del dataframe de items\n",
    "ml_items_df = pd.read_csv('data/movielens/ml_items.csv', sep='|',\n",
    "    names=['Id Película','Título','Fecha de estreno','Fecha DVD','iMDB','Género desconocido','Acción','Aventura','Animación','Infantil','Comedia', 'Crimen','Docuemntal','Drama','Fantasía','Cine negro','Horror','Musical','Misterio','Romance','Ciencia ficción','Thriller','Bélico','Western'],\n",
    "    encoding='latin-1')\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices   \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "ml_dataset = Dataset()\n",
    "ml_dataset.fit(ml_data_df['Id Usuario'], ml_data_df['Id Película'])\n",
    "ml_dataset.fit_partial(users=ml_user_df['Id Usuario'], items=ml_items_df['Id Película'],\n",
    "                    user_features=ml_user_df['Género'], item_features=ml_items_df['Título'])\n",
    "\n",
    "#num_users, num_items = ml_dataset.interactions_shape()\n",
    "#print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "# Obtención de las matrices\n",
    "(ml_interactions, ml_weights) = ml_dataset.build_interactions((row['Id Usuario'], row['Id Película'], row['Valoración']) for index, row in ml_data_df.iterrows())\n",
    "ml_item_features = ml_dataset.build_item_features((row['Id Película'], [row['Título']]) for index, row in ml_items_df.iterrows())\n",
    "ml_user_features = ml_dataset.build_user_features((row['Id Usuario'], [row['Género']]) for index, row in ml_user_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1d3831949b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_collab_model = LightFM(loss='warp')\n",
    "ml_collab_model.fit(ml_interactions, sample_weight=ml_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "    Known positives:\n",
      "        Get Shorty (1995)\n",
      "        Twelve Monkeys (1995)\n",
      "        Dead Man Walking (1995)\n",
      "    Recommended:\n",
      "         Pinocchio (1940)\n",
      "         Searching for Bobby Fischer (1993)\n",
      "         Grosse Pointe Blank (1997)\n",
      "User 25\n",
      "    Known positives:\n",
      "        Babe (1995)\n",
      "        Dead Man Walking (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         Rumble in the Bronx (1995)\n",
      "         Young Guns (1988)\n",
      "         Free Willy 3: The Rescue (1997)\n",
      "User 450\n",
      "    Known positives:\n",
      "        Twelve Monkeys (1995)\n",
      "        Babe (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         Spawn (1997)\n",
      "         Natural Born Killers (1994)\n",
      "         Weekend at Bernie's (1989)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(ml_collab_model, ml_interactions, [3, 25, 450], ml_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1d38289a5f8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_hybrid_model = LightFM(loss='warp')\n",
    "ml_hybrid_model.fit(ml_interactions, item_features=ml_item_features, sample_weight=ml_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "    Known positives:\n",
      "        Get Shorty (1995)\n",
      "        Twelve Monkeys (1995)\n",
      "        Dead Man Walking (1995)\n",
      "    Recommended:\n",
      "         Spawn (1997)\n",
      "         Theodore Rex (1995)\n",
      "         Pinocchio (1940)\n",
      "User 25\n",
      "    Known positives:\n",
      "        Babe (1995)\n",
      "        Dead Man Walking (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         My Life as a Dog (Mitt liv som hund) (1985)\n",
      "         Young Guns (1988)\n",
      "         Free Willy 3: The Rescue (1997)\n",
      "User 450\n",
      "    Known positives:\n",
      "        Twelve Monkeys (1995)\n",
      "        Babe (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         Spawn (1997)\n",
      "         Natural Born Killers (1994)\n",
      "         Aristocats, The (1970)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(ml_hybrid_model, ml_interactions, [3, 25, 450], ml_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1d38289a470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_content_model = LightFM(loss='warp')\n",
    "ml_content_model.fit(ml_interactions, user_features=ml_user_features, item_features=ml_item_features, sample_weight=ml_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "    Known positives:\n",
      "        Get Shorty (1995)\n",
      "        Twelve Monkeys (1995)\n",
      "        Dead Man Walking (1995)\n",
      "    Recommended:\n",
      "         My Life as a Dog (Mitt liv som hund) (1985)\n",
      "         Doom Generation, The (1995)\n",
      "         Dead Man Walking (1995)\n",
      "User 25\n",
      "    Known positives:\n",
      "        Babe (1995)\n",
      "        Dead Man Walking (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         Desperate Measures (1998)\n",
      "         Gay Divorcee, The (1934)\n",
      "         Ulee's Gold (1997)\n",
      "User 450\n",
      "    Known positives:\n",
      "        Twelve Monkeys (1995)\n",
      "        Babe (1995)\n",
      "        Seven (Se7en) (1995)\n",
      "    Recommended:\n",
      "         Spawn (1997)\n",
      "         Birdcage, The (1996)\n",
      "         Forrest Gump (1994)\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(ml_content_model, ml_interactions, [3, 25, 450], ml_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención del dataframe de items\n",
    "anime_items_df = pd.read_csv('data/anime/anime.csv', sep=',', \n",
    "    names=['Id Anime', 'Título', 'Género', 'Tipo', 'Episodios', 'Valoración Media', 'Miembros'])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#anime_items_df\n",
    "\n",
    "# Obtención del dataframe de datos\n",
    "anime_data1_df = pd.read_csv('data/anime/ratings1.csv', sep=',', names=['Id Usuario', 'Id Anime', 'Valoración'], low_memory=False)\n",
    "anime_data2_df = pd.read_csv('data/anime/ratings2.csv', sep=',', names=['Id Usuario', 'Id Anime', 'Valoración'], low_memory=False)\n",
    "anime_data3_df = pd.read_csv('data/anime/ratings3.csv', sep=',', names=['Id Usuario', 'Id Anime', 'Valoración'], low_memory=False)\n",
    "anime_data4_df = pd.read_csv('data/anime/ratings4.csv', sep=',', names=['Id Usuario', 'Id Anime', 'Valoración'], low_memory=False)\n",
    "anime_data_df = pd.concat([anime_data1_df, anime_data2_df, anime_data3_df, anime_data4_df])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#anime_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices  \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "anime_dataset = Dataset()\n",
    "anime_dataset.fit(anime_data_df['Id Usuario'], anime_data_df['Id Anime'])\n",
    "anime_dataset.fit_partial(items=anime_items_df['Id Anime'], item_features=anime_items_df['Título'])\n",
    "\n",
    "#num_users, num_items = anime_dataset.interactions_shape()\n",
    "#print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "# Obtención de las matrices\n",
    "(anime_interactions, anime_weights) = anime_dataset.build_interactions((row['Id Usuario'], row['Id Anime'], row['Valoración']) for index, row in anime_data_df.iterrows())\n",
    "anime_item_features = anime_dataset.build_item_features((row['Id Anime'], [row['Título']]) for index, row in anime_items_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1d382896588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_collab_model = LightFM(loss='warp')\n",
    "anime_collab_model.fit(anime_interactions, sample_weight=anime_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "    Known positives:\n",
      "        Steins;Gate\n",
      "        Sen to Chihiro no Kamikakushi\n",
      "        Ookami Kodomo no Ame to Yuki\n",
      "    Recommended:\n",
      "         Sore Ike! Anpanman: Omusubiman\n",
      "         Minami no Kuni kara Kita Tegami\n",
      "         Digimon Adventure tri. 4: Soushitsu\n",
      "User 25\n",
      "    Known positives:\n",
      "        Ookami Kodomo no Ame to Yuki\n",
      "        Monogatari Series: Second Season\n",
      "        Fate/Zero 2nd Season\n",
      "    Recommended:\n",
      "         Sore Ike! Anpanman: Omusubiman\n",
      "         Minami no Kuni kara Kita Tegami\n",
      "         Digimon Adventure tri. 4: Soushitsu\n",
      "User 450\n",
      "    Known positives:\n",
      "        Kimi no Na wa.\n",
      "        Fullmetal Alchemist: Brotherhood\n",
      "        Ginga Eiyuu Densetsu\n",
      "    Recommended:\n",
      "         Gintama: Shiroyasha Koutan\n",
      "         Cardcaptor Sakura Movie 2: Fuuin Sareta Card\n",
      "         Steins;Gate\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(anime_collab_model, anime_interactions, [3, 25, 450], anime_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1d382896710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anime_hybrid_model = LightFM(loss='warp')\n",
    "# Comentar la línea que no proceda\n",
    "anime_hybrid_model.fit(anime_interactions, item_features=anime_item_features, sample_weight=anime_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 3\n",
      "    Known positives:\n",
      "        Steins;Gate\n",
      "        Sen to Chihiro no Kamikakushi\n",
      "        Ookami Kodomo no Ame to Yuki\n",
      "    Recommended:\n",
      "         Tough Guy!\n",
      "         Venus\n",
      "         Saenggakboda Markeun\n",
      "User 25\n",
      "    Known positives:\n",
      "        Ookami Kodomo no Ame to Yuki\n",
      "        Monogatari Series: Second Season\n",
      "        Fate/Zero 2nd Season\n",
      "    Recommended:\n",
      "         Tough Guy!\n",
      "         Venus\n",
      "         Saenggakboda Markeun\n",
      "User 450\n",
      "    Known positives:\n",
      "        Kimi no Na wa.\n",
      "        Fullmetal Alchemist: Brotherhood\n",
      "        Ginga Eiyuu Densetsu\n",
      "    Recommended:\n",
      "         Gintama: Shiroyasha Koutan\n",
      "         Steins;Gate\n",
      "         Cardcaptor Sakura Movie 2: Fuuin Sareta Card\n"
     ]
    }
   ],
   "source": [
    "sample_recommendation(anime_hybrid_model, anime_interactions, [3, 25, 450], anime_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book-Crossing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "field larger than field limit (131072)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m   2577\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2578\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2579\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: field larger than field limit (131072)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f3cc5c98cc61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Obtención del dataframe de datos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbc_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/book-crossing/BX-Book-Ratings.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id Usuario'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ISBN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Valoración'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Descomentar para comprobar que el dataframe se ha obtenido correctamente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#bc_data_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python-fwf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFixedWidthFieldParser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m   1965\u001b[0m         \u001b[1;31m# infer column indices from self.usecols if is is specified.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_col_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_original_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m         \u001b[1;31m# Now self.columns has the set of columns that we will process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2340\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2341\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2342\u001b[1;33m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffered_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2344\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_buffered_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2411\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2413\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2415\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_for_bom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_next_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2517\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2518\u001b[1;33m                 \u001b[0morig_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2519\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m   2598\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'. '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2600\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_alert_malformed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2601\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_alert_malformed\u001b[1;34m(self, msg, row_num)\u001b[0m\n\u001b[0;32m   2557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2559\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mParserError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2560\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_bad_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[0mbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Skipping line {row_num}: '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: field larger than field limit (131072)"
     ]
    }
   ],
   "source": [
    "# Obtención del dataframe de datos\n",
    "bc_data_df = pd.read_csv('data/book-crossing/BX-Book-Ratings.csv', sep=';', names=['Id Usuario','ISBN','Valoración'], engine='python', escapechar='\"')\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#bc_data_df\n",
    "\n",
    "# Obtención del dataframe de usuarios\n",
    "bc_user_df = pd.read_csv('data/book-crossing/BX-Users.csv', names=['Id Usuario', 'Residencia', 'Edad'])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#bc_user_df\n",
    "\n",
    "# Obtención del dataframe de items\n",
    "bc_items_df = pd.read_csv('data/book-crossing/BX-Books.csv', names=['ISBN','Título','Autor','Fecha de publicación','Editorial','URL S','URL M','URL L'])\n",
    "\n",
    "# Descomentar para comprobar que el dataframe se ha obtenido correctamente\n",
    "#bc_items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención del dataset y de las matrices  \n",
    "Convierto los dataframes en las estructuras de datos que necesita LightFM para poder sacar las matrices y poder hacer uso de su sistema de recomendación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtención de los dataset\n",
    "bc_dataset = Dataset()\n",
    "bc_dataset.fit(bc_data_df['Id Usuario'], bc_data_df['ISBN'])\n",
    "bc_dataset.fit_partial(users=bc_user_df['Id Usuario'], items=bc_items_df['ISBN'],\n",
    "                    user_features=bc_user_df['Edad'], item_features=bc_items_df['Título'])\n",
    "\n",
    "#num_users, num_items = bc_dataset.interactions_shape()\n",
    "#print('Num users: {}, num_items {}.'.format(num_users, num_items))\n",
    "\n",
    "# Obtención de las matrices\n",
    "(bc_interactions, bc_weights) = bc_dataset.build_interactions((row['Id Usuario'], row['ISBN'], row['Valoración']) for index, row in bc_data_df.iterrows())\n",
    "bc_item_features = bc_dataset.build_item_features((row['ISBN'], [row['Título']]) for index, row in bc_items_df.iterrows())\n",
    "bc_user_features = bc_dataset.build_user_features((row['Id Usuario'], [row['Edad']]) for index, row in bc_user_df.iterrows())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo colaborativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_collab_model = LightFM(loss='warp')\n",
    "bc_collab_model.fit(bc_interactions, sample_weight=bc_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_recommendation(bc_collab_model, bc_interactions, [3, 25, 450], bc_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo híbrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_hybrid_model = LightFM(loss='warp')\n",
    "bc_hybrid_model.fit(bc_interactions, item_features=bc_item_features, sample_weight=bc_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_recommendation(bc_hybrid_model, bc_interactions, [3, 25, 450], bc_items_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo por contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bc_content_model = LightFM(loss='warp')\n",
    "bc_content_model.fit(bc_interactions, user_features=bc_user_features, item_features=bc_item_features, sample_weight=bc_weights, epochs=30, num_threads=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_recommendation(bc_content_model, bc_interactions, [3, 25, 450], bc_items_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
